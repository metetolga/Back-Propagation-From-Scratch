{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from module.nn import MLP, Layer, Neuron, softmax_score\n",
    "from module.loss import CrossEntropyLoss\n",
    "from module.optim import SGD\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=5, n_classes=10, n_informative=5, n_clusters_per_class=2, n_redundant=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = OneHotEncoder(sparse_output=False).fit_transform(y.reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = Layer(in_shape=5, out_shape=8, activation='relu')\n",
    "layer1 = Layer(in_shape=8, out_shape=10, activation='relu')\n",
    "layer2 = Layer(in_shape=10, out_shape=10) \n",
    "\n",
    "NUM_FEATURES = len(X[0])\n",
    "NUM_CLASSES = 2\n",
    "nn = MLP(in_shape=NUM_FEATURES, out_shape=NUM_CLASSES)\n",
    "\n",
    "nn.add_layer(layer0)\n",
    "nn.add_layer(layer1)\n",
    "nn.add_layer(layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DENEME\n",
    "logits = nn(X)\n",
    "pred = softmax_score(logits)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = nn(X)\n",
    "pred = softmax_score(logits)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4325974495688135\n",
      "1 0.4322046838770555\n",
      "2 0.4318116615535895\n",
      "3 0.4314135271498249\n",
      "4 0.4310220007539902\n",
      "5 0.43062539361168606\n",
      "6 0.43022789778963605\n",
      "7 0.4298377467919574\n",
      "8 0.42944002870533354\n",
      "9 0.42903976240934527\n",
      "10 0.4286398554229433\n",
      "11 0.42824335740137337\n",
      "12 0.4278514408111461\n",
      "13 0.427463968598051\n",
      "14 0.4270807031178284\n",
      "15 0.4266973588766596\n",
      "16 0.42631407931070203\n",
      "17 0.4259345139405989\n",
      "18 0.4255586078691279\n",
      "19 0.4251861667866563\n",
      "20 0.42482141209132346\n",
      "21 0.424466741967034\n",
      "22 0.4241154591719857\n",
      "23 0.42376752062659684\n",
      "24 0.42342289653434984\n",
      "25 0.42308155114082424\n",
      "26 0.42274345207605885\n",
      "27 0.4224085647573649\n",
      "28 0.4220768556777313\n",
      "29 0.42177198647499764\n",
      "30 0.4214739294371217\n",
      "31 0.42117679612733633\n",
      "32 0.420883641702132\n",
      "33 0.4205934927354465\n",
      "34 0.42029696174107856\n",
      "35 0.41999677994631057\n",
      "36 0.4196983852346323\n",
      "37 0.41940145418872854\n",
      "38 0.4191079081283924\n",
      "39 0.4188173362094993\n",
      "40 0.41855071661475884\n",
      "41 0.41830958064074963\n",
      "42 0.4180710369504687\n",
      "43 0.41782722170336994\n",
      "44 0.41758658722500075\n",
      "45 0.4173492013372335\n",
      "46 0.41711335871139177\n",
      "47 0.41687889789351285\n",
      "48 0.4166473686853809\n",
      "49 0.4164187454422129\n",
      "50 0.416193030904815\n",
      "51 0.4159684828723228\n",
      "52 0.4157436312785999\n",
      "53 0.41552162806006615\n",
      "54 0.4153003791853032\n",
      "55 0.41508099331042936\n",
      "56 0.41486437840084095\n",
      "57 0.41464064238705367\n",
      "58 0.4144038855626722\n",
      "59 0.4141684229016657\n",
      "60 0.4139366871259146\n",
      "61 0.4136963005982173\n",
      "62 0.41345700611142583\n",
      "63 0.41322055976776656\n",
      "64 0.41298687072734525\n",
      "65 0.4127558437485713\n",
      "66 0.41252853846263615\n",
      "67 0.4123031793752912\n",
      "68 0.4120804842565999\n",
      "69 0.4118607650385098\n",
      "70 0.41164336547379876\n",
      "71 0.4114280748792183\n",
      "72 0.4112151608960529\n",
      "73 0.411004596149292\n",
      "74 0.41079599310346526\n",
      "75 0.4105802916104132\n",
      "76 0.41036684746375734\n",
      "77 0.41015578996868146\n",
      "78 0.40994715081747296\n",
      "79 0.40974090348695413\n",
      "80 0.40953702304357664\n",
      "81 0.409335998576393\n",
      "82 0.40913770376883796\n",
      "83 0.4089441182669482\n",
      "84 0.4087691245935249\n",
      "85 0.4085962841982078\n",
      "86 0.4084262314311104\n",
      "87 0.40825823969144753\n",
      "88 0.40809229837481104\n",
      "89 0.40792839349994936\n",
      "90 0.4077665071051385\n",
      "91 0.40760613412424274\n",
      "92 0.4074443224219979\n",
      "93 0.4072837501910045\n",
      "94 0.4071243670682224\n",
      "95 0.4069671551070313\n",
      "96 0.40679611728188486\n",
      "97 0.40662580556127625\n",
      "98 0.4064453469164016\n",
      "99 0.40626219102312994\n",
      "100 0.40608353440147427\n",
      "101 0.4059055396499954\n",
      "102 0.4057168794280246\n",
      "103 0.40553651421384646\n",
      "104 0.4053606727832741\n",
      "105 0.40518683096246383\n",
      "106 0.40501564513235216\n",
      "107 0.4048469243809777\n",
      "108 0.40468021956858946\n",
      "109 0.4045153736292674\n",
      "110 0.40435225631966676\n",
      "111 0.4041908300774786\n",
      "112 0.4040310613567087\n",
      "113 0.4038729205839853\n",
      "114 0.4037163804011906\n",
      "115 0.4035625282580217\n",
      "116 0.4034106761598399\n",
      "117 0.4032603870177635\n",
      "118 0.40311872405630267\n",
      "119 0.4029834457610364\n",
      "120 0.4028502880584516\n",
      "121 0.402719187121577\n",
      "122 0.4025891931115072\n",
      "123 0.4024606226023801\n",
      "124 0.4023277173915236\n",
      "125 0.40218176425626745\n",
      "126 0.40203733225504656\n",
      "127 0.40189477642685767\n",
      "128 0.4017543770697177\n",
      "129 0.40161543232210584\n",
      "130 0.40147792360189377\n",
      "131 0.4013418284500771\n",
      "132 0.40121469380634295\n",
      "133 0.4010901350917626\n",
      "134 0.40096875949458444\n",
      "135 0.4008435758919275\n",
      "136 0.4007188699238106\n",
      "137 0.4005952190054141\n",
      "138 0.4004726206240373\n",
      "139 0.4003510580360309\n",
      "140 0.40023052276804455\n",
      "141 0.4001110071284799\n",
      "142 0.39999301914922997\n",
      "143 0.39987606917500196\n",
      "144 0.3997601364886853\n",
      "145 0.39964499332864856\n",
      "146 0.39953083582159893\n",
      "147 0.3994176995086115\n",
      "148 0.39930599040543435\n",
      "149 0.39919543296128124\n",
      "150 0.39908576053675326\n",
      "151 0.3989769133297957\n",
      "152 0.39886897483512157\n",
      "153 0.3987620266691836\n",
      "154 0.3986560642311675\n",
      "155 0.39855108236363285\n",
      "156 0.3984470753892561\n",
      "157 0.39834463659440544\n",
      "158 0.3982451538189733\n",
      "159 0.39814719296209594\n",
      "160 0.3980505883402517\n",
      "161 0.3979500750762124\n",
      "162 0.39782805711597474\n",
      "163 0.39770804344936117\n",
      "164 0.39759354024993115\n",
      "165 0.39748073436123726\n",
      "166 0.3973692675054777\n",
      "167 0.39725921379926127\n",
      "168 0.39714882812947766\n",
      "169 0.3970177450268624\n",
      "170 0.3968761154060439\n",
      "171 0.39673537931799935\n",
      "172 0.39659089545087384\n",
      "173 0.3964473640891851\n",
      "174 0.3963046625475134\n",
      "175 0.39616815775802855\n",
      "176 0.39604160596628163\n",
      "177 0.3959158299902259\n",
      "178 0.39579081018294454\n",
      "179 0.39566655225098785\n",
      "180 0.3955430180317196\n",
      "181 0.3954202023267676\n",
      "182 0.3952982399658781\n",
      "183 0.39517911348623347\n",
      "184 0.3950607151884819\n",
      "185 0.39494025369025787\n",
      "186 0.3948186622224937\n",
      "187 0.39469754564961557\n",
      "188 0.39457700302789867\n",
      "189 0.3944577891073975\n",
      "190 0.394338737674947\n",
      "191 0.3942202689914266\n",
      "192 0.39410507593222327\n",
      "193 0.39399085130775396\n",
      "194 0.3938755349016248\n",
      "195 0.3937598023490093\n",
      "196 0.3936465063996921\n",
      "197 0.3935338835751294\n",
      "198 0.3934218095051268\n",
      "199 0.39331044254573905\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 0.1\n",
    "loss_func = CrossEntropyLoss()\n",
    "optimizer = SGD(parameters=nn.parameters(), lr=lr)\n",
    "for epoch in range(epochs):\n",
    "    # forward pass\n",
    "    y_logits = nn(X)\n",
    "    y_pred = softmax_score(y_logits)\n",
    "    loss = loss_func(y_pred, y)\n",
    "\n",
    "    # zero grad \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # backward pass \n",
    "    loss.backward() \n",
    "\n",
    "    # gradient descent\n",
    "    optimizer.step()\n",
    "\n",
    "    print(epoch, loss.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_venv",
   "language": "python",
   "name": "base_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
